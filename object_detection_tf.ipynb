{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxmDMK4yupqg"
   },
   "source": [
    "# Object Detection using Tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4XGxDrCkeip"
   },
   "source": [
    "## Import Required Library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing tensorflow library\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Tensorflow version\n",
    "print(tf.__version__)\n",
    "\n",
    "# Check available GPU devices.\n",
    "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "execution": {
     "iopub.execute_input": "2021-11-05T11:46:57.137885Z",
     "iopub.status.busy": "2021-11-05T11:46:57.137202Z",
     "iopub.status.idle": "2021-11-05T11:47:00.711417Z",
     "shell.execute_reply": "2021-11-05T11:47:00.711841Z"
    },
    "id": "6cPY9Ou4sWs_"
   },
   "outputs": [],
   "source": [
    "# For running inference on the TF-Hub module.\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# For downloading the image.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For drawing onto the image.\n",
    "import numpy as np\n",
    "from PIL import Image, ImageColor, ImageDraw, ImageFont, ImageOps\n",
    "\n",
    "# For measuring the inference time.\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlA3CftFpRiW"
   },
   "source": [
    "### Function for showing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    plt.grid(False)\n",
    "    plt.imshow(image) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for loading and resize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_resize(file_path, new_width=256, new_height=256,display=False):\n",
    "  \n",
    "    pil_image = Image.open(file_path) # for opening Image\n",
    "    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS) # for resizing image to 256 * 256 ANTIALIAS is filter\n",
    "\n",
    "    if display:\n",
    "        show_image(pil_image)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create bounding box over object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box_over_object(image, y_min, x_min, y_max, x_max, color, font, thickness=7, display_str_list=()):\n",
    "    \n",
    "    \"\"\"Adds a bounding box to an image.\"\"\"\n",
    "    draw = ImageDraw.Draw(image) # used to draw object over images\n",
    "    im_width, im_height = image.size\n",
    "    \n",
    "    (left, right, top, bottom) = (x_min * im_width, x_max * im_width, y_min * im_height, y_max * im_height)\n",
    "    \n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),(left, top)],width=thickness,fill=color)\n",
    "\n",
    "    ''' \n",
    "    If the total height of the display strings added to the top of the bounding\n",
    "    box exceeds the top of the image, stack the strings below the bounding box\n",
    "    instead of above.\n",
    "    '''\n",
    "    display_str_heights = [font.getsize(list_val)[1] for list_val in display_str_list]\n",
    "    \n",
    "    # Each display_str has a top and bottom margin of 0.05x.\n",
    "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "    if top > total_display_str_height:\n",
    "        text_bottom = top\n",
    "    else:\n",
    "        text_bottom = top + total_display_str_height\n",
    "        \n",
    "    # Reverse list and print from bottom to top.\n",
    "    for display_str in display_str_list[::-1]:\n",
    "        \n",
    "        text_width, text_height = font.getsize(display_str)\n",
    "        margin = np.ceil(0.05 * text_height)\n",
    "        draw.rectangle([(left, text_bottom - text_height - 2 * margin),  (left + text_width, text_bottom)], fill=color)\n",
    "        \n",
    "        draw.text((left + margin, text_bottom - text_height - margin), display_str, fill=\"black\", font=font)\n",
    "        text_bottom -= text_height - 2 * margin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to draw boxes if score is >= Min Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T11:47:00.728650Z",
     "iopub.status.busy": "2021-11-05T11:47:00.727816Z",
     "iopub.status.idle": "2021-11-05T11:47:00.730321Z",
     "shell.execute_reply": "2021-11-05T11:47:00.729908Z"
    },
    "id": "D9IwDpOtpIHW"
   },
   "outputs": [],
   "source": [
    "\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.12):\n",
    "    \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
    "    colors = list(ImageColor.colormap.values()) # create list of color from various colors\n",
    "\n",
    "    #font = ImageFont.load_default()\n",
    "    font = ImageFont.truetype('arial.ttf', 15)\n",
    "\n",
    "    for i in range(min(boxes.shape[0], max_boxes)):\n",
    "        if scores[i] >= min_score:\n",
    "            y_min, x_min, y_max, x_max = tuple(boxes[i])\n",
    "            display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),int(100 * scores[i]))\n",
    "            color = colors[hash(class_names[i]) % len(colors)]\n",
    "            image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
    "            bounding_box_over_object(image_pil, y_min, x_min, y_max, x_max, color, font, thickness=7, display_str_list=[display_str])\n",
    "            np.copyto(image, np.array(image_pil))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D19UCu9Q2-_8"
   },
   "source": [
    "### Apply module\n",
    "\n",
    "> Tensorflow module provide various API to directly run detection.\n",
    "<br>\n",
    "> Here,module dataset taken is Open Images v4 , and saved locally to detect objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-VdfLbC1w51"
   },
   "source": [
    "Pick an object detection module and apply on the images\n",
    "<br>\n",
    "Various tensorflow object detection API are there.\n",
    "<br>\n",
    "Modules used : \n",
    "\n",
    ">* **ssd+mobilenet V2**: small and fast,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T11:47:02.369404Z",
     "iopub.status.busy": "2021-11-05T11:47:02.368550Z",
     "iopub.status.idle": "2021-11-05T11:48:20.675154Z",
     "shell.execute_reply": "2021-11-05T11:48:20.675628Z"
    },
    "id": "uazJ5ASc2_QE"
   },
   "outputs": [],
   "source": [
    "module_handle = \"openimages_v4_ssd_mobilenet_v2_1\"\n",
    "#module_handle = \"faster_rcnn_openimages_v4_inception_resnet_v2_1\"\n",
    "detector = hub.load(module_handle).signatures['default']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input:\n",
    "A three-channel image of variable size - the model does NOT support batching. The input tensor is a tf.float32 tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The output dictionary contains:\n",
    "\n",
    "detection_boxes: a tf.float32 tensor of shape [N, 4] containing bounding box coordinates in the following order: [ymin, xmin, ymax, xmax].\n",
    "<br><br>\n",
    "detection_class_entities: a tf.string tensor of shape [N] containing detection class names as Freebase MIDs.\n",
    "<br><br>\n",
    "detection_class_names: a tf.string tensor of shape [N] containing human-readable detection class names.\n",
    "<br><br>\n",
    "detection_class_labels: a tf.int64 tensor of shape [N] with class indices.\n",
    "<br><br>\n",
    "detection_scores: a tf.float32 tensor of shape [N] containing detection scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load images decode them into 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T11:48:20.680802Z",
     "iopub.status.busy": "2021-11-05T11:48:20.680142Z",
     "iopub.status.idle": "2021-11-05T11:48:20.682000Z",
     "shell.execute_reply": "2021-11-05T11:48:20.682383Z"
    },
    "id": "znW8Fq1EC0x7"
   },
   "outputs": [],
   "source": [
    "def load_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to run object detector with inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T11:48:20.688428Z",
     "iopub.status.busy": "2021-11-05T11:48:20.687774Z",
     "iopub.status.idle": "2021-11-05T11:48:20.690041Z",
     "shell.execute_reply": "2021-11-05T11:48:20.689580Z"
    },
    "id": "kwGJV96WWBLH"
   },
   "outputs": [],
   "source": [
    "def run_detector(detector, path):\n",
    "    img = load_img(path)\n",
    "\n",
    "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
    "    start_time = time.time()\n",
    "    result = detector(converted_img)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    \n",
    "    \n",
    "    result = {key:value.numpy() for key,value in result.items()}\n",
    "    #print(result['detection_boxes'], result['detection_class_entities'],result['detection_class_names'],result['detection_class_labels'],result['detection_scores'])\n",
    "    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
    "    print(\"Inference time: \", end_time-start_time)\n",
    "\n",
    "    image_with_boxes = draw_boxes(img.numpy(), result[\"detection_boxes\"],result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
    "\n",
    "    show_image(image_with_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUUY3nfRX7VF"
   },
   "source": [
    "###  File Path of Images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_img(image_path):\n",
    "    image_path = load_image_resize(image_path, 640, 480)\n",
    "    run_detector(detector, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"test_images/people.png\"\n",
    "detect_img(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T11:48:59.395120Z",
     "iopub.status.busy": "2021-11-05T11:48:59.394114Z",
     "iopub.status.idle": "2021-11-05T11:48:59.396667Z",
     "shell.execute_reply": "2021-11-05T11:48:59.396155Z"
    },
    "id": "rubdr2JXfsa1"
   },
   "outputs": [],
   "source": [
    "image_path = [\n",
    "  \"test_images/traffic.jpg\",\n",
    "    \"test_images/pedestrian.jpg\",\n",
    "  ]\n",
    "for i in range(len(image_path)):\n",
    "    detect_img(image_path[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"test_images/dog_cat.jpg\"\n",
    "detect_img(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"test_images/beach.jpg\"\n",
    "detect_img(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_video_detector(detector, image_np):\n",
    "\n",
    "    converted_img  = tf.image.convert_image_dtype(image_np, tf.float32)[tf.newaxis, ...]\n",
    "    start_time = time.time()\n",
    "    result = detector(converted_img)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    \n",
    "    \n",
    "    result = {key:value.numpy() for key,value in result.items()}\n",
    "    #print(result['detection_boxes'], result['detection_class_entities'],result['detection_class_names'],result['detection_class_labels'],result['detection_scores'])\n",
    "    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
    "    print(\"Inference time: \", end_time-start_time)\n",
    "\n",
    "    image_with_boxes = draw_boxes(image_np, result[\"detection_boxes\"],result[\"detection_class_entities\"], result[\"detection_scores\"],min_score=0.20)\n",
    "\n",
    "    show_image(image_with_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_video_detector():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        # Read frame from camera\n",
    "        ret, image_np = cap.read()\n",
    "\n",
    "        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "        input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "        result = detector(input_tensor)\n",
    "        \n",
    " \n",
    "        image_np_with_detections = image_np.copy()\n",
    "\n",
    "        run_video_detector(detector, image_np_with_detections)\n",
    "        # Display output\n",
    "        cv2.imshow('Object Detection', cv2.resize(image_np_with_detections, (1024, 780)))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "call_video_detector()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Object detection",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
